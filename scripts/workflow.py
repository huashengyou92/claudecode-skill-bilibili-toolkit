#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Bilibili å®Œæ•´å·¥ä½œæµç¨‹è„šæœ¬
Complete Workflow: Search â†’ Filter â†’ Download Subtitles â†’ Analyze â†’ Report

ä½¿ç”¨æ–¹æ³•:
    python workflow.py "å…³é”®è¯" --max-videos 10
"""

import os
import sys
import json
import argparse
from datetime import datetime
from collections import Counter
from typing import List, Dict, Optional
import re

# å¯¼å…¥å…¶ä»–æ¨¡å—
from bilibili_search import BilibiliSearch
from bilibili_downloader import BilibiliDownloader


class BilibiliWorkflow:
    """Bç«™è§†é¢‘åˆ†æå®Œæ•´å·¥ä½œæµç¨‹"""

    def __init__(self, cookies: Optional[Dict] = None):
        """
        åˆå§‹åŒ–å·¥ä½œæµç¨‹

        Args:
            cookies: Bilibili cookies (å¯é€‰ï¼Œä»é…ç½®æ–‡ä»¶è‡ªåŠ¨åŠ è½½)
        """
        self.searcher = BilibiliSearch()
        self.downloader = BilibiliDownloader(cookies=cookies)
        self.results = {
            'keyword': '',
            'search_time': '',
            'videos': [],
            'subtitles': [],
            'analysis': {},
            'report_path': ''
        }

    def search_videos(self, keyword: str, max_results: int = 20) -> List[Dict]:
        """
        æœç´¢è§†é¢‘

        Args:
            keyword: æœç´¢å…³é”®è¯
            max_results: æœ€å¤§ç»“æœæ•°

        Returns:
            è§†é¢‘åˆ—è¡¨
        """
        print(f"\n[INFO] æ­£åœ¨æœç´¢å…³é”®è¯: {keyword}")
        print(f"[INFO] è·å–å‰ {max_results} ä¸ªç»“æœ...")

        videos = self.searcher.search_videos(keyword, page=1, page_size=max_results)

        if not videos:
            print(f"[WARN] æ²¡æœ‰æ‰¾åˆ°ç›¸å…³è§†é¢‘")
            return []

        print(f"[OK] æ‰¾åˆ° {len(videos)} ä¸ªè§†é¢‘\n")

        # æ˜¾ç¤ºæœç´¢ç»“æœ
        for idx, video in enumerate(videos, 1):
            print(f"{idx}. {video['title']}")
            print(f"   UPä¸»: {video['author']} | æ’­æ”¾: {video['play']:,} | æ—¶é•¿: {video['duration']}")
            print(f"   é“¾æ¥: {video['url']}")
            print()

        self.results['keyword'] = keyword
        self.results['search_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        self.results['videos'] = videos

        return videos

    def filter_videos(self, videos: List[Dict], auto_select: bool = True,
                     top_n: Optional[int] = None) -> List[Dict]:
        """
        ç­›é€‰è§†é¢‘

        Args:
            videos: è§†é¢‘åˆ—è¡¨
            auto_select: æ˜¯å¦è‡ªåŠ¨é€‰æ‹©
            top_n: è‡ªåŠ¨é€‰æ‹©å‰Nä¸ªï¼ˆæŒ‰æ’­æ”¾é‡æ’åºï¼‰

        Returns:
            ç­›é€‰åçš„è§†é¢‘åˆ—è¡¨
        """
        if not videos:
            return []

        if auto_select:
            if top_n:
                # æŒ‰æ’­æ”¾é‡æ’åºå¹¶é€‰æ‹©å‰Nä¸ª
                sorted_videos = sorted(videos, key=lambda x: x['play'], reverse=True)
                selected = sorted_videos[:top_n]
                print(f"[INFO] è‡ªåŠ¨é€‰æ‹©æ’­æ”¾é‡æœ€é«˜çš„ {len(selected)} ä¸ªè§†é¢‘")
            else:
                selected = videos
                print(f"[INFO] é€‰æ‹©æ‰€æœ‰ {len(selected)} ä¸ªè§†é¢‘")
        else:
            # æ‰‹åŠ¨é€‰æ‹©æ¨¡å¼ï¼ˆäº¤äº’å¼ï¼‰
            print("\n[INFO] è¯·è¾“å…¥è¦ä¸‹è½½å­—å¹•çš„è§†é¢‘åºå·ï¼ˆç”¨é€—å·åˆ†éš”ï¼Œå¦‚: 1,3,5ï¼‰")
            print("[INFO] æˆ–è¾“å…¥ 'all' é€‰æ‹©æ‰€æœ‰è§†é¢‘")

            choice = input("é€‰æ‹©: ").strip()

            if choice.lower() == 'all':
                selected = videos
            else:
                try:
                    indices = [int(x.strip()) for x in choice.split(',')]
                    selected = [videos[i-1] for i in indices if 0 < i <= len(videos)]
                except (ValueError, IndexError):
                    print("[WARN] æ— æ•ˆçš„é€‰æ‹©ï¼Œå°†é€‰æ‹©æ‰€æœ‰è§†é¢‘")
                    selected = videos

        return selected

    def download_subtitles(self, videos: List[Dict]) -> List[Dict]:
        """
        ä¸‹è½½è§†é¢‘å­—å¹•

        Args:
            videos: è§†é¢‘åˆ—è¡¨

        Returns:
            æˆåŠŸä¸‹è½½çš„å­—å¹•ä¿¡æ¯åˆ—è¡¨
        """
        print(f"\n[INFO] å¼€å§‹ä¸‹è½½ {len(videos)} ä¸ªè§†é¢‘çš„å­—å¹•...")

        # ä½¿ç”¨å·¥ä½œåŒºç›®å½•
        workspace_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', '..', '..', 'bilibili-workspace'))
        subtitles_dir = os.path.join(workspace_dir, 'subtitles')
        os.makedirs(subtitles_dir, exist_ok=True)

        successful_downloads = []

        for idx, video in enumerate(videos, 1):
            print(f"\n[{idx}/{len(videos)}] å¤„ç†: {video['title']}")

            try:
                # æå–BV ID
                bvid = self.downloader.extract_bvid(video['url'])
                if not bvid:
                    print(f"[WARN] æ— æ³•æå–BV ID")
                    continue

                # è·å–è§†é¢‘ä¿¡æ¯
                info = self.downloader.get_video_info(bvid)
                if not info:
                    print(f"[WARN] æ— æ³•è·å–è§†é¢‘ä¿¡æ¯")
                    continue

                cid = info['cid']
                title = info['title']

                # è·å–å­—å¹•
                print(f"[INFO] æ­£åœ¨è·å–å­—å¹•ï¼ˆå¸¦éªŒè¯æœºåˆ¶ï¼‰...")
                subtitles = self.downloader.get_subtitles(bvid, cid)

                if not subtitles:
                    print(f"[WARN] è¯¥è§†é¢‘æ²¡æœ‰å­—å¹•")
                    continue

                # åªå¤„ç†ä¸­æ–‡å­—å¹•
                chinese_subtitle = None
                for sub in subtitles:
                    if 'zh' in sub.get('lan', '').lower() or 'chi' in sub.get('lan', '').lower():
                        chinese_subtitle = sub
                        break

                if not chinese_subtitle:
                    print(f"[WARN] æ²¡æœ‰æ‰¾åˆ°ä¸­æ–‡å­—å¹•")
                    continue

                # ä¿å­˜å­—å¹•ä¸ºçº¯æ–‡æœ¬ï¼ˆæ ¼å¼ï¼šBVå·_æ ‡é¢˜.txtï¼‰
                safe_title = "".join(c for c in title if c.isalnum() or c in (' ', '-', '_')).strip()
                safe_title = safe_title[:50]  # é™åˆ¶æ–‡ä»¶åé•¿åº¦
                output_path = os.path.join(subtitles_dir, f"{bvid}_{safe_title}.txt")

                self.downloader.save_subtitle_as_text(chinese_subtitle, output_path)

                # è¯»å–å­—å¹•å†…å®¹ç”¨äºåˆ†æ
                with open(output_path, 'r', encoding='utf-8') as f:
                    subtitle_text = f.read()

                successful_downloads.append({
                    'video': video,
                    'bvid': bvid,
                    'subtitle_path': output_path,
                    'subtitle_text': subtitle_text,
                    'word_count': len(subtitle_text)
                })

                print(f"[OK] å­—å¹•å·²ä¿å­˜: {output_path}")

            except Exception as e:
                print(f"[ERROR] ä¸‹è½½å¤±è´¥: {str(e)}")
                continue

        print(f"\n[INFO] æˆåŠŸä¸‹è½½ {len(successful_downloads)}/{len(videos)} ä¸ªè§†é¢‘çš„å­—å¹•")

        self.results['subtitles'] = successful_downloads

        return successful_downloads

    def analyze_content(self, subtitles: List[Dict]) -> Dict:
        """
        åˆ†æå­—å¹•å†…å®¹

        Args:
            subtitles: å­—å¹•ä¿¡æ¯åˆ—è¡¨

        Returns:
            åˆ†æç»“æœ
        """
        print(f"\n[INFO] æ­£åœ¨åˆ†æ {len(subtitles)} ä¸ªè§†é¢‘çš„å­—å¹•å†…å®¹...")

        if not subtitles:
            return {}

        # åˆå¹¶æ‰€æœ‰å­—å¹•æ–‡æœ¬
        all_text = ""
        for sub in subtitles:
            all_text += sub['subtitle_text'] + "\n"

        # åŸºç¡€ç»Ÿè®¡
        total_chars = len(all_text)
        total_lines = all_text.count('\n')

        # åˆ†è¯å¹¶ç»Ÿè®¡è¯é¢‘ï¼ˆç®€å•çš„ä¸­æ–‡åˆ†è¯ - 2-3å­—è¯ï¼‰
        words = []
        for line in all_text.split('\n'):
            line = line.strip()
            if not line:
                continue
            # æå–2-3å­—çš„ä¸­æ–‡è¯ç»„
            for i in range(len(line) - 1):
                if '\u4e00' <= line[i] <= '\u9fff':  # ä¸­æ–‡å­—ç¬¦
                    # 2å­—è¯
                    if i + 1 < len(line) and '\u4e00' <= line[i+1] <= '\u9fff':
                        words.append(line[i:i+2])
                    # 3å­—è¯
                    if i + 2 < len(line) and '\u4e00' <= line[i+1] <= '\u9fff' and '\u4e00' <= line[i+2] <= '\u9fff':
                        words.append(line[i:i+3])

        # è¯é¢‘ç»Ÿè®¡ï¼ˆæ’é™¤å•å­—å’Œè¿‡äºå¸¸è§çš„è¯ï¼‰
        stop_words = {'è¿™ä¸ª', 'ä¸€ä¸ª', 'æˆ‘ä»¬', 'ä½ ä»¬', 'ä»–ä»¬', 'ä»€ä¹ˆ', 'æ€ä¹ˆ', 'å¯ä»¥', 'å°±æ˜¯', 'å› ä¸º', 'æ‰€ä»¥', 'ä½†æ˜¯', 'ç„¶å', 'å¦‚æœ', 'è¿™æ ·', 'é‚£ä¹ˆ', 'å·²ç»', 'æ²¡æœ‰', 'ä¸æ˜¯', 'è¿˜æ˜¯'}
        word_freq = Counter([w for w in words if len(w) >= 2 and w not in stop_words])
        top_keywords = word_freq.most_common(30)

        # è§†é¢‘æ—¶é•¿ç»Ÿè®¡
        total_duration_mins = sum(
            self._parse_duration(sub['video']['duration'])
            for sub in subtitles
        )

        # æ’­æ”¾é‡ç»Ÿè®¡
        total_plays = sum(sub['video']['play'] for sub in subtitles)
        avg_plays = total_plays // len(subtitles) if subtitles else 0

        analysis = {
            'video_count': len(subtitles),
            'total_chars': total_chars,
            'total_lines': total_lines,
            'total_duration_mins': total_duration_mins,
            'total_plays': total_plays,
            'avg_plays': avg_plays,
            'top_keywords': top_keywords,
            'videos_summary': [
                {
                    'title': sub['video']['title'],
                    'author': sub['video']['author'],
                    'play': sub['video']['play'],
                    'duration': sub['video']['duration'],
                    'word_count': sub['word_count'],
                    'url': sub['video']['url']
                }
                for sub in subtitles
            ]
        }

        self.results['analysis'] = analysis

        print(f"[OK] åˆ†æå®Œæˆ")
        print(f"    - æ€»å­—ç¬¦æ•°: {total_chars:,}")
        print(f"    - æ€»è¡Œæ•°: {total_lines:,}")
        print(f"    - æ€»æ—¶é•¿: {total_duration_mins:.1f} åˆ†é’Ÿ")
        print(f"    - æ€»æ’­æ”¾é‡: {total_plays:,}")
        print(f"    - å¹³å‡æ’­æ”¾é‡: {avg_plays:,}")

        return analysis

    def _parse_duration(self, duration_str: str) -> float:
        """è§£ææ—¶é•¿å­—ç¬¦ä¸²ä¸ºåˆ†é’Ÿæ•°"""
        try:
            parts = duration_str.split(':')
            if len(parts) == 2:
                return int(parts[0]) + int(parts[1]) / 60
            elif len(parts) == 3:
                return int(parts[0]) * 60 + int(parts[1]) + int(parts[2]) / 60
        except:
            pass
        return 0

    def generate_report(self, output_dir: str = None) -> str:
        """
        ç”Ÿæˆåˆ†ææŠ¥å‘Š

        Args:
            output_dir: æŠ¥å‘Šè¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ä½¿ç”¨å·¥ä½œåŒºç›®å½•ï¼‰

        Returns:
            æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        # ä½¿ç”¨å·¥ä½œåŒºç›®å½•
        if output_dir is None:
            workspace_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', '..', '..', 'bilibili-workspace'))
            output_dir = os.path.join(workspace_dir, 'reports')
        print(f"\n[INFO] æ­£åœ¨ç”Ÿæˆåˆ†ææŠ¥å‘Š...")

        os.makedirs(output_dir, exist_ok=True)

        # ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶å
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        keyword_safe = "".join(c for c in self.results['keyword'] if c.isalnum() or c in (' ', '-', '_')).strip()
        keyword_safe = keyword_safe.replace(' ', '_')[:20]
        report_filename = f"bilibili_report_{keyword_safe}_{timestamp}.md"
        report_path = os.path.join(output_dir, report_filename)

        # ç”ŸæˆMarkdownæŠ¥å‘Š
        analysis = self.results.get('analysis', {})
        subtitles = self.results.get('subtitles', [])

        with open(report_path, 'w', encoding='utf-8') as f:
            # æ ‡é¢˜
            f.write(f"# Bilibili è§†é¢‘åˆ†ææŠ¥å‘Š\n\n")
            f.write(f"**å…³é”®è¯:** {self.results['keyword']}\n\n")
            f.write(f"**åˆ†ææ—¶é—´:** {self.results['search_time']}\n\n")
            f.write("---\n\n")

            # æ‘˜è¦
            f.write("## ğŸ“Š æ•°æ®æ‘˜è¦\n\n")
            if analysis:
                f.write(f"- **è§†é¢‘æ•°é‡:** {analysis['video_count']} ä¸ª\n")
                f.write(f"- **æ€»å­—å¹•å­—ç¬¦æ•°:** {analysis['total_chars']:,} å­—\n")
                f.write(f"- **æ€»å­—å¹•è¡Œæ•°:** {analysis['total_lines']:,} è¡Œ\n")
                f.write(f"- **æ€»è§†é¢‘æ—¶é•¿:** {analysis['total_duration_mins']:.1f} åˆ†é’Ÿ\n")
                f.write(f"- **æ€»æ’­æ”¾é‡:** {analysis['total_plays']:,}\n")
                f.write(f"- **å¹³å‡æ’­æ”¾é‡:** {analysis['avg_plays']:,}\n")
            f.write("\n")

            # çƒ­é—¨å…³é”®è¯
            f.write("## ğŸ”¥ çƒ­é—¨å…³é”®è¯ï¼ˆTop 30ï¼‰\n\n")
            if analysis and 'top_keywords' in analysis:
                f.write("| æ’å | å…³é”®è¯ | å‡ºç°æ¬¡æ•° |\n")
                f.write("|------|--------|----------|\n")
                for idx, (word, count) in enumerate(analysis['top_keywords'], 1):
                    f.write(f"| {idx} | {word} | {count} |\n")
            f.write("\n")

            # è§†é¢‘åˆ—è¡¨
            f.write("## ğŸ“¹ è§†é¢‘åˆ—è¡¨\n\n")
            if analysis and 'videos_summary' in analysis:
                for idx, video in enumerate(analysis['videos_summary'], 1):
                    f.write(f"### {idx}. {video['title']}\n\n")
                    f.write(f"- **UPä¸»:** {video['author']}\n")
                    f.write(f"- **æ’­æ”¾é‡:** {video['play']:,}\n")
                    f.write(f"- **æ—¶é•¿:** {video['duration']}\n")
                    f.write(f"- **å­—å¹•å­—æ•°:** {video['word_count']:,}\n")
                    f.write(f"- **é“¾æ¥:** [{video['url']}]({video['url']})\n")
                    f.write("\n")

            # å­—å¹•æ–‡ä»¶
            f.write("## ğŸ“ å­—å¹•æ–‡ä»¶\n\n")
            if subtitles:
                f.write("æ‰€æœ‰å­—å¹•å·²ä¿å­˜åˆ°ä»¥ä¸‹æ–‡ä»¶ï¼š\n\n")
                for idx, sub in enumerate(subtitles, 1):
                    f.write(f"{idx}. `{sub['subtitle_path']}`\n")
            f.write("\n")

            # é¡µè„š
            f.write("---\n\n")
            f.write("*æœ¬æŠ¥å‘Šç”± Bilibili Toolkit è‡ªåŠ¨ç”Ÿæˆ*\n")

        self.results['report_path'] = report_path

        print(f"[OK] æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")

        return report_path

    def run(self, keyword: str, max_videos: int = 10, auto_select: bool = True) -> Dict:
        """
        è¿è¡Œå®Œæ•´å·¥ä½œæµç¨‹

        Args:
            keyword: æœç´¢å…³é”®è¯
            max_videos: æœ€å¤§è§†é¢‘æ•°
            auto_select: æ˜¯å¦è‡ªåŠ¨é€‰æ‹©è§†é¢‘

        Returns:
            å®Œæ•´çš„ç»“æœå­—å…¸
        """
        print("=" * 60)
        print("Bilibili è§†é¢‘åˆ†æå·¥ä½œæµç¨‹")
        print("=" * 60)

        # 1. æœç´¢è§†é¢‘
        videos = self.search_videos(keyword, max_results=max_videos * 2)
        if not videos:
            print("[ERROR] æœç´¢å¤±è´¥ï¼Œå·¥ä½œæµç¨‹ç»ˆæ­¢")
            return self.results

        # 2. ç­›é€‰è§†é¢‘
        selected_videos = self.filter_videos(videos, auto_select=auto_select, top_n=max_videos)
        if not selected_videos:
            print("[ERROR] æ²¡æœ‰é€‰æ‹©ä»»ä½•è§†é¢‘ï¼Œå·¥ä½œæµç¨‹ç»ˆæ­¢")
            return self.results

        # 3. ä¸‹è½½å­—å¹•
        subtitles = self.download_subtitles(selected_videos)
        if not subtitles:
            print("[WARN] æ²¡æœ‰æˆåŠŸä¸‹è½½ä»»ä½•å­—å¹•")
            return self.results

        # 4. åˆ†æå†…å®¹
        analysis = self.analyze_content(subtitles)

        # 5. ç”ŸæˆæŠ¥å‘Š
        report_path = self.generate_report()

        print("\n" + "=" * 60)
        print("å·¥ä½œæµç¨‹å®Œæˆ!")
        print("=" * 60)
        print(f"[OK] åˆ†ææŠ¥å‘Š: {report_path}")
        print(f"[OK] å­—å¹•æ–‡ä»¶: ./subtitles/")

        return self.results


def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    parser = argparse.ArgumentParser(
        description='Bilibili è§†é¢‘åˆ†æå®Œæ•´å·¥ä½œæµç¨‹',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # æœç´¢å…³é”®è¯å¹¶åˆ†æå‰10ä¸ªè§†é¢‘
  python workflow.py "Pythonç¼–ç¨‹"

  # æŒ‡å®šæœ€å¤§è§†é¢‘æ•°
  python workflow.py "äººå·¥æ™ºèƒ½" --max-videos 5

  # æ‰‹åŠ¨é€‰æ‹©è§†é¢‘
  python workflow.py "æœºå™¨å­¦ä¹ " --manual
        """
    )

    parser.add_argument('keyword', help='æœç´¢å…³é”®è¯')
    parser.add_argument('--max-videos', type=int, default=10, help='æœ€å¤§è§†é¢‘æ•°é‡ï¼ˆé»˜è®¤: 10ï¼‰')
    parser.add_argument('--manual', action='store_true', help='æ‰‹åŠ¨é€‰æ‹©è§†é¢‘ï¼ˆé»˜è®¤: è‡ªåŠ¨é€‰æ‹©ï¼‰')

    args = parser.parse_args()

    # è¿è¡Œå·¥ä½œæµç¨‹
    workflow = BilibiliWorkflow()

    try:
        results = workflow.run(
            keyword=args.keyword,
            max_videos=args.max_videos,
            auto_select=not args.manual
        )

        # æ˜¾ç¤ºç»“æœæ‘˜è¦
        if results.get('report_path'):
            print(f"\n[INFO] æŸ¥çœ‹å®Œæ•´æŠ¥å‘Š: {results['report_path']}")

    except KeyboardInterrupt:
        print("\n[INFO] ç”¨æˆ·ä¸­æ–­")
        sys.exit(0)
    except Exception as e:
        print(f"\n[ERROR] å·¥ä½œæµç¨‹å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()
